<h1>Part III : Learning about x86</h1>
<h2>The theory being covered</h2>
<p>
    There are only really four things we need to learn about before continuing to make our bootloader
    And these are: 
</p>
<ul>
    <li>x86 Operating Modes</li>
    <li>x86 Memory Segmentation (not to be confused with segmentation in disk drives)</li>
    <li>The x86 Run-time Stack</li>
    <li>x86 Interrupts</li>
</ul>
<p>So let's start, tackling these in order.</p>
<h2>x86 Operating Modes</h2>
<p>
    There are two modes we will be working with in x86, these are 16-bit real 
    mode and 32-bit protected mode, but what exactly is an operating mode?
    An operating mode refers to a specific configuration in 
    which the CPU operates, each mode defines how the CPU interacts with memory, hardware 
    and software, they each offer many different features, capabilities, and limitations.
</p>
<p>
    To be expected, protected and real mode are not the only modes in
    x86, there is long mode (which only exists in 64 bit systems), compatibility mode (which is 16 bit)
    and many others.
    But as we are writing a 32-bit x86 operating system our only goal is to get into 
    protected mode which is mainly used for modern operating systems and software, which is what we are making.
    When we started writing our OS in the last chapter, we were working in 
    real mode, as real mode is the initial operating mode of x86 processors during 
    system boot-up.
</p>
<p>Here is everything about real mode:</p>
<ul>
    <li>
        Real mode is a minimalist environment, unsuprisingly
        providing only the essential features required to bootstrap a computer 
        system. It lacks many advanced features that we will need to access in protected mode, 
        Such as memory protection
    </li>
    <li>
        Real mode also has direct access to resources without 
        abstraction layers or OS intervention. Which allows for low 
        level manipulation of hardware components.
        It also allows access of BIOS interrupts, which (like we used before)
        are commonly used during system boot-up and for low-level system 
        programming tasks performed in real mode. BIOS interrupts provide a way for software 
        to interact with the system BIOS.
    </li>
    <li>
        Now, onto limitations, the most important is probably a lack 
        of memory protection (which, if you like cybersecurity, you'd be
        interested in), real mode offers absolutely no memory protection 
        mechanisms, leaving the system utterly vulnerable to memory corruption and 
        unauthorized access. Software running in real mode can freely access and modify 
        any memory location, leading to security and stability issues.
    </li>
</ul>
<p>And now, let's talk about Protected Mode:</p>
<ul>
    <li>
        The advantages for protected mode are really just the disadvantages of Real mode.
        It has Memory Protection, Multitasking support, privilege levels, among other things.
    </li>
    <li>
        However, protected mode provides additional complexity compared to
        real mode due to its advanced features mentioned before.
    </li>
</ul>
<p>
    That just about sums up what we need to know about our x86 operating modes, 
    as a summary, we are currently in real mode and need to get into our protected mode to get 
    many useful features for making our own OS.
</p>
<h2>x86 Memory Segmentation</h2>
<p>
    What is memory? Well, physically we can think of memory as just 
    an array of bytes, each having a memory address that is just a numerical value 
    stored in base 16, this is our physical view of memory, however we need a logical 
    view of memory that can make alot of things much easier. This is where memory segmentation comes in.
</p>
<p>
    Memory segmentation in x86 architecture is a feature that 
    divides the memory into segments to allow for more flexible
    memory management and protection. Understanding it is extremely 
    important when developing an operating system for x86 platforms as in 
    real mode, memory segmentation is the default and primary mechanism for 
    adressing memory. In protected mode, memory segmentation is still the default 
    memory adressing scheme, but it can be configured or optimised to work alongside or be 
    bypassed in favour of other memory management methods like paging.
</p>
<p>
    Memory segmentation isn't really used in the modern day; it's an old way of formulating memory and
    is used on x86 because of physical design factors of the CPU. Whereas paging mostly is, which we will
    likely use in our operating system, we will get into that much later.
</p>
<p>
    Memory segmentation works differently in real mode and protected mode 
    so let's look at them individually, starting with a basic overview and then 
    looking at how it's done in real mode.
</p>
<h2 style="font-size: 20px;">How does memory segmentation work? An overview.</h2>
<p>
    First, let's look at a basic overview of how memory segmentation works,
    Segmentation is where main memory is seperated into parts called segments where 
    each segment stores related data. To access data inside a segment, each byte is 
    referred to by it's own offset.
    A running program is split into 3 different segments in x86, these are:
</p>
<ul>
    <li>
        Code segment: Stores code of the program under execution
    </li>
    <li>
        Data segment: Stores the data of the program
    </li>
    <li>
        Stack segment: Stores the data of the program's stack
    </li>
</ul>
<h2 style="font-size: 20px;">How does memory segmentation work in real mode?</h2>
<p>
    We will start with real mode just so we can be clear without having to cover all of the extra stuff you 
    have to consider in protected mode (like global descriptor tables). Here in real mode, segmentation is mapped
    by the view of the processor itself, so as said before, there is no way to avoid it.
    It is also worth mentioning that each segment in real mode is 64KB in size.
    In real mode, we have segment registers with each register having a size of 16 bits, these registers are:
    <ul>
        <li>
            CS: used to define a code segment
        </li>
        <li>
            SS: used to define a stack segment
        </li>
        <li>
            DS: used to define a data segment
        </li>
    </ul>
    <p>There are also a few other registers that we can use:</p>
    <ul>
        <li>
            ES: additional segment register that provides flexibility in memory access,
            usually used when you need to access more segments without changing the value of ds
        </li>
        <li>
            GS: global segment register, made to provide a segment for global data but can be used 
            similarly to ES
        </li>
        <li>
            FS: file segment register, made to access local thread storage but can also be used similarly to ES
        </li>
    </ul>
    <p>Each segment stores the starting memory address of a segment. We can reach any byte in a segment by setting an offset
</p>
<p>Let's look at an example for memory segmentation.</p>
<p>
    Assume we have some code for a program loaded into memory, which is stored at 100d. To reach the first byte we would clearly 
    just set our offset to 0, and increase it for any next byte we want to access.
    We would also set the cs register to 100d as that is the starting address for the current code segment we are
    trying to run.
</p>
<p>
    x86 always runs with memory segmentation in mind, so when we use the jmp instruction, we aren't jumping to a
    specific space in memory, so let's say we write jmp 100d, we are actually jumping to the offset of 100d inside the 
    current code segment. This also happens internally with the PC (program counter), where the PC doesn't
    store the full memory address, just the offset of the next instruction.
    Any jump to a location in the same code segment is called a near jump/call, otherwise it is called a far jump
    To do far jumps, you can do stuff like "<span class="hljs">jmp 900:1d</span>", this will load 900d into the 
    CS and 1d into the PC. 
</p>
<p>
    This is exactly the same for the other two segments (data and stack), it was just easy to demonstrate using 
    and jump/call because the functionality is related to code which is easy to manipulate code flow.
    An example for DS would be lodsb, and for SS, the push instruction.
</p>
<h2 style="font-size: 20px;">How was memory segmentation used in the bootloader?</h2>
<p>
    Previously, when we wrote the bootloader (and the basic kernel) we dealt with segments, let's look at our code
    and I can now explain it now that you know everything you need to know about memory segmentation in real mode.
</p>
<p>
    The first thing we will look at goes all the way back to when we wrote our printing code together, this 
    is in the start label, here:
</p>

<pre><code>mov ax, 07C0h
mov ds, ax</code></pre>

<p>
    It's worth noting that the CS register is already set to <span class="hljs">07C0h</span> by the bootloader
    but we also set the same value to the DS register, This ensures the bootloader can correctly access it's own code and data
    correctly.
    But you might ask: "why do we need to load the location into ax and then ds?". This is because we can't directly load 
    into segment registers due to multiple limitations on the instruction set, so we just use ax as an intermediary register in order 
    to load into ds.
</p>

<p>Moving on, the next place we used memory segmentation</p>

<p>
    This is when we were trying to load the kernel into memory from the bootloader, More specifically it was when 
    we were trying to use the 13:02h interrupt, which is the interrupt for taking code from storage into memory.
    Which can all be seen in this code here: 
</p>

<pre><code>load_kernel_from_disk:
mov ax, 0900h
mov es, ax

mov ah, 02h ; service number, 
mov al, 01h ; number of sectors we want to read from (only simple kernel for now, so less than 512 bytes)

mov ch, 0h ; number of track we would like to read from, is just 0.
mov cl, 02h ; sector number that we would like to read its content, this is the second sector

mov dh, 0h ; the type of disk we would like to read from, 0h means we are reading from a floppy disk. 
mov dl, 80h ; this is the hard disk we are reading from, 80h means hard disk #0, 81h would be hard disk #1

mov bx, 0h ; memory adress that content will be loaded into
int 13h ; 13h provides services related to hard disk</code></pre>

<p>
    Here, what we do first is store 0900h into the extra segment register, as this is where we will be storing 
    the kernel in memory, you see, the interrupt 13h:02h loads the content (which we have defined with 
    prior registers) into the memory adress es:bx (where bx is the offset).
</p>

<p>
    Then after we do that we can commit a far jump to the next memory segment where the kernel will be stored.
    It's worth noting that a far jump changes the value of the cs register to wherever you jump to, in this case, it 
    will be set to 0900h, which is good because that's where the start of code segment for our kernel is.
    Then, in our kernel, we can set the ds register to the same as the cs in order to read code and data from the 
    same segment.
</p>


<h2 style="font-size: 20px;">How does memory segmentation work in protected mode? An intro to the Global Descriptor Table.</h2>

<p>
    So we have got down how memory segmentation works in real mode, and even know how it's used in our bootloader,
    that's pretty good, now we've just got to cover protected mode and we're done with memory segmentation and can move 
    onto the run time stack.
</p>


<p>
    So, the basics of memory segmentation in protected mode and real mode are basically the same.
    But, protected mode comes with some extra extensions for certain features like memory protection.
</p>

<p>
    In protected mode, we have something called the global descriptor table (GDT), this is stored in main 
    memory, and it's base address is referenced by the global descriptor table register (GDTR). Just to clarify the GDTR is a special 
    register used by the CPU to point to the location of the GDT in memory.
</p>

<p>
    Each entry in this table is called a segment descriptor, each segment descriptor has a size of 
    8 bytes and can be reffered to by an index called a segment selector. The segment selector defines an 
    offset of 8 bytes within the space defined by the GDTR.
    Each entry in the GDT defines a segment (of any type) and has the info required by the CPU to deal with that segment.
    For instance: The starting memory address of the segment is stored, the size/limit of the segment is stored.
</p>

<p>
    Furthermore, as we have this focus around the GDT, our segment registers from real mode no longer store direct addresses,
    they store segment selectors.
</p>

<h4>The structure of the segment descriptor, a basic overview.</h4>

<p>
    As we said before, a segment descriptor is an entry of the GDT worth 8 bytes, it is made up of multiple fields and flags that describe the attributes of any 
    segment in memory. The processor will then go to the descriptor that describes the segment when we need to obtain information about a segment, like the starting memory address (of said segment).
    Aswell as storing basic info, a segment descriptor stores info that helps in memory protection, this makes memory segmentation not just a logical way of viewing memory, but a method of memory protection,
    protecting different segments on the system from each other, and not letting a less privileged segments manipulate data or call code in certain places (typically more privileged areas of the system).

</p>

<h4>How segments are used when calling and interacting with other memory.</h4>

<p>
    The most important information about a segment is it's base address (the starting memory address). In real mode, the base address was stored in the corresponding segment register directly,
    but in protected mode, this is just stored in the segment descriptor.
</p>

<p>
    When currently running code refers to a memory address to read from or write to (with data segments) or to call somewhere (with code segments). it is actually referencing a specific
    segment in the system and an offset. This generated memory address that we get when we try to look somewhere in a different segment, is not a physical memory adress, it is actually a logical memory address,
    meaning it doesn't actually reference the place in which data is stored, it is simply a logical representation of where we need to go relative to the program's address space.
    In this case, a logical memory address is a segment selector and offset, to point to the memory location we want to go.
</p>

<p>
    Every logical memory address refers to some byte in the specific segment in the system, and to actually reference this, it needs to be translated into a physical memory address.
</p>

<p>
    In x86, a logical memory address may go through two translation processes instead of one, to obtain a physical memory address.
    The first step: involves turning the logical memory address into a linear memory address (another non physical memory address) which is here becuase of the paging feature. If paging is enables in
    the system, a second translation process occurs to turn the linear memory addresss into a physical memory address, this is becauase a linear memory address can be seen as a physical address when paging is disabled.
    But not when it is enabled. So for now, we will only focus on the process to turn a logical memory address into a linear memory address.
</p>

<p>
    So, we know that each logical address consists of two parts, a 16 bit segment selector and a 32 bit offset. When this is logical adress is generated by currently running code, the proccessor then 
    needs to ranslate it to get the physical address, as has been said.
</p>

<p>
    First we read the value of the register GDTR (which contains the starting physical memory address to locate the descriptor of the GDT), then we use the segment selector in the logical
    memory address in order to locate the descriptor of the segment, this descriptor then contains the base address of the segment, the proccessor then obtains this base address, and adds it to the offset,
    this provides ups with the linear memory address.
</p>

<h4>Memory protection in this process, and segment limits.</h4>

<p>
    During this process of translation, other information from the segment descriptor is used to provide memory protection. One of these pieces of information is called the limit of a segment,
    this means a segment's size, if the generated code refers to an offset which exceeds the limit of a segment, the proccessor will stop this operation.
</p>

<p>
    The limit of a segment is stored in the 20 bit "segment limit field" of a segment descriptor, how to processor interprets the value of the segment limit field depends on the 
    granularity flag (G flag), which is also stored in the segment's descriptor. When the value of the G flag is 0, this means te value of the limit field is interpreted as bytes.
    So if the G flag is set to 0 and the segment limit field is 20, the size of the segment is seen as 20 bytes. On the other hand, when it 
    is set to 1, the value of the segment limit field will be interpreted as 4KB units. To see what this means, assume the value of the limit field is 20, but the G flag is 1, this means that the size 
    of the segment will be 20 of 4KB units, so 20*4 = 80, so the size of the segment is 80KB, (81920 bytes).
</p>

<p>
    Because the size of the segment limit field is 20 bits, this means that the max numeric value it can represent is 2^20, this means that is the G flag is 0, the mximum size is 1MB, and if
    it's set to 1, the maximum size is 4 GB.
</p>

<h4>Back to the structure of the descriptor, looking more in depth.</h4>

<p>
    I can show you the complete structure of a descriptor using a diagram taken from the "Intel® 64 and IA-32 Architectures Software Developer’s Manual (Volume 3A)", seen here:
</p>

<img src="/images/os/segdescriptor.png" style="width: 746px; height: 422px;">

<p>
    The first 16 bits (bit 0-15) are the first 16 bits of the segment's limit. then next 24 are the first 24 bits of the segment's base, then we have our type field, S flag, DPL field, P flag,
    then we have the next nibble of our limit, the AVL flag, L flag (for 64 bit), DB flag, G flag, and the next section of our base.
</p>

<p>
    You may be wondering, why is the segment descriptor formatted so strangely? and it's simply becuase of reverse compatibility with the 80286 16-bit microproccessor, here is a similar 
    diagram seen from the Intel 80286 Programmer's Reference Manual:
</p>

<img src="/images/os/olddescriptor.png" style="width: 746px; height: 422px;">

<p>On the 80286 diagram, the base size was 24 bits, and the limit's size was 16 bits, therefore we just extend this for our newer proccessor architecture.</p>

<h4>A segment's type</h4>

<p>
    When a segment is defined, the processor should know how to interpret the content inside this segment, this is defined by the type of segment. We know so far that there are code segments 
    and data segments, these two types belong to a category of segments called application segments, there is another category called system segments, and many types of segment belong to it.
</p>

<p>
    Whether a specific segment is an application or system segment, is defined in the S flag, also known as the descriptor type flag, which is the fifth bit in the fifth byte of the segment descriptor.
    When the S flag is 0, the segment is considered a system segment, when it is an application segment the value of S is 1. We will focus on when the S flag is 1.
</p>
 
<p>
    The only application segments are code and data. If some application segment is referenced by currently running code, the proccessor will go to the descriptor of this segment, 
    and by reading the S flag (which sould be 1), it should know that the segment in question is an application segment, but how does it know whether it's a data or code segment?
    This info is stored in a field called the type field in the segment descriptor.
</p>

<p>
    The type field is the first 4 bits of the 5th byte of the segment descriptor. The most significant bit specifies if the application segment is a code or data segment, the least significant 
    specifies whether the segment has been accessed or not, when the value of this is 1, this means that the segment has been written to or read from, but if it's 0, this means that the segment 
    has not been accessed. The value of this bit is changed by the proccessor in only one situation, this is when the selector of the segment is loaded into the GDT. In any other situation, 
    it's up to the OS to decide the value of the accessed flag. According to intel, this flag can be used for virtual memory management and debugging.
</p>

<p>
    The other two bits or flags of the type field depend on whether it's a code or data segment. So let's cover those individually.
</p>

<h4>The type field for Code segments</h4>

<p>
    When the segment is a code segment, the second most significant bit of the type field is called the conforming flag (C flag), whereas the third most significant bit is called the 
    read-enabled (R flag), starting with the simplest being the R flag.
</p>

<p>
    The value of this flag indicates how the code inside the segment can be used, when the value of the R flag is 1, this means
    the content of the code can be executed and read from, but when it's 0, this means that is can be only be executed, and not read from.  
</p>

<p>
    The conforming flag is all to do with privilege levels. When a segment is conforming (the value of the conforming flag is 1), this means that code that runs in a less-priveleged level 
    can call this segment which runs in at a higher privilege level. Why would we want this? Well the kernel can sometimes provide code that is basic and may be needed by many programs,
    this code would have a privilege level of 0, as it is a part of the kernel and would gain the highest privelege level, however, any other programs, which would have a lower privelege level
    wouldn't really be able to call this without the conforming flag. So this is why it is needed.
</p>

<h4>The type field for Data segments</h4>

<p>
    Now, when we are working with data segments, the second most significant bit is called the expansion-direction flag (E flag), and the third most significant is called the write-enabled flag 
    (W flag)
</p>

<p>
    The write-enabled flag gives the ability to decide whether we want our data segment to be read-only or not, when set to 0, the data will be read-only, when set to 1, the data segment will be both
    readable and writable
</p>

<p>
    The expansion-direction flag will be covered when i move onto the x86 run-time stack, for a vague definition now, we could say that when the value of the flag is 0, the data segment
    is going to expand up, but when the value of the flag is 1, the data segment will expand down. (these are intel's terms so don't blame me).
</p>

<p>
    An extra thing about data segments is that all of them are non-conforming, which means, less priveleged code cannot access a data in a more priveleged level, and all data segments 
    can be accessed by a more-priveleged code.
</p>

<h4>Privelege levels in segments</h4>

<p>
    Prior, i have probably stated that a segment should belong to a privelege level, and based on this, there are rules for how certain segments can interact based on these privelege levels
    which the processor would enforce, these privelege levels are defined by the descriptor privelege level (DPL) in the segment descriptor, as this is a 2 bit value, the possible privelege levels 
    are 0, 1, 2 and 3, the DPL is int he second and third most significant bits of byte 5 in a descriptor.
</p>

<h4>The other flags: The D/B flag</h4>

<p>
    There are only 3 flags left that i haven't covered, the first is a flag which name changes depending on the segment it resides within, it is located within the second 
    most significant bit in byte 6 when it within a code segment, it is called the 
    default operation size flag (D flag), When the processor executes the instructions, it uses the D flag to choose the lenght of the operands, depending on the currently executing instruction.
    If the value of the D flag is 1, the processor is going to assume the operand has a size of 32 bits if it's a memory address, and 32 bits or 8 bits if it's not a memory address, when the value of the 
    D flag is 0, the processor is going to assume the the operand has the size of 16 bits if it's a memory address, and 16 or 8 bits if not a memory address.
</p>

<p>
    When the segment is a stack segment, the same flag is calle dthe default stack pointer size flag (B flag), and it decides the size of the memory address which points to the stack,
    which is commonly known as the stack pointer, used by stack instructions such as push and pop. When the value of the B flag is 1, then the size of the stack pointer will be 
    32 bits, and it's value will be stored in the register ESP, when the value of the B flag is 0, the size of the stack pointer will be 16 bits and it's value will be stored 
    in the register SP
</p>

<p>
    When dealing with a data segment that grows upward, this is called an upper bound flag (B flag), when it's value is 1, the maximum possible size of the segment will be 4GB, otherwise, the 
    maximum size is 64KB
</p>

<p>To note, the value of the D/B flag should usually be 1 for 32 bit segments and 0 for 16 bit segments.</p>

<h4>The other flags: The L flag</h4>

<p>
    This is known as the 64-bit code segment flag (L flag), which is the third most significant bit in the byte 6. If the value of this flag is 1 that means the code inside this segment 
    is 64-bit code while 0 means the opposite, when the value of the L flag is 1, the D/B flag should be 0.
</p>

<h4>The other flags: The AVL flag</h4>

<p>
    This flag doensn't really have any paticular meaning for the processor, however, this flag is availible for the OS to use in whatever way it needs, or it is just ignored.
</p>

<p>And that wraps up all coverage of the descriptor, moving on.</p>

<h4>More on the GDTR</h4>

<p>
    As we know, the GDTR stores the base (physical) address of the global descriptor table, but it also stores the limit of the table.
    To load a value into the register of the GDTR the instruction: <span class="hljs">lgdt</span> 
    must be used, this stands for "load global descriptor table". It takes one operand which is the value that should be loaded into the GDTR,
    this operand's structure should be similar to the actual structure of the GDTR, which is shown here:
</p>

<img src="/images/os/GDTR diagram.png">

<p>
    We can see it's 48 bits long, starting with the 16 bit limit, and then the 32 bit base. The operand should follow this same formula.
    This also means that we have some limits to our GDTR (no pun intended), as our limit is a 16 bit number, the maximum value of our GDT 
    is 64KB (65536) bytes.
</p>

<h4>The local descriptor table</h4>

<p>
    The GDT is system-wide, this means that it is available to every single process within the system. x86 also gives us the power to create local descriptor tables (LDTs) in protected-mode,
    these have the same functionality and structure as the GDT. Multiple of these LDT's can be made, each one can be private to a specific process currently running on the system, multiple 
    processes can also share a single LDT that only those proccesses can interact with, and no other processes will be able to interact with this LDT. 
</p>

<p>
    How to use an LDT depends on how the kernel is being designed, whereas the GDT is required by x86 architecture, the LDT is optional and in the hands of the designer.
    To tell the processor that a given region of memory is in an LDT, a new segment descriptor should be created in the GDT for the LDT, the LDT table will be considered as a 
    system segment, so the value of the S flag would be 0, and because there are many different system segments in x86 we would then have to define that this is an LDT.
    This is done via the type field, and it's value should be 0010b, how the processor can tell which table should be used in the monment for a given segment between the 
    GDT and the LDT will be discussed when we talk about segment selectors.
</p>

<p>
    The x86 inscrustion lldt is used to load the LDT table that we would like to use now into a special register called the LDTR, which is 16-bit and contains the index of the segment 
    descriptor which describes the LDT table.
</p>

<h4>More on the segment selector</h4>

<p>
    In reality, the way how we described the segment selector before as an index, is not actually true, the index is simply just a single part of the segment selector,
    a full diagram of it can be seen here:
</p>

<img src="/images/os/segmentselector.png">

<p>
    We can see that it is 16 bits and the first two bits are occupied by a field called the "requester privelege level" (RPL). The next bit is then occupied by a flag called the table indicator,
    and then we have our usual index field which we know much about.
</p>

<p>
    The TI flag is used by the processor to tell if the index in the segment selector is an index in the GDT or the LDT, when it is at 0, the index signifies the GDT, when it is at 1, it 
    signifies an LDT, when it's 1, the processor consults the LDTR to know which LDT we are working with, then the descriptor on the LDT is read.
</p>

<p>
    The RPL, as the name suggests, is to do with privelege levels, we mentioned before the DPL, the privelege level of a given segment and there also exists the CPL, 
    which is the privelege level of the currently executing code, the RPL is used when a low privelege program calls let's say, kernel data that is a more high privelege,
    when calling, the RPL defines the privelege level of the caller, so any attempts to reach a segment where its sectors RPL is larger than the CPL should be denied.
</p>

<!-- maybe cover the CPL in proccesor modes -->

<h2>x86 Run-Time Stack</h2>

<p>
    I'll assume you already know how the stack data structure works regularly without a context as it's one of the most basic data sructures in computer science, if you don't, do not worry,
    as it's super simple and there are many great explanations <a href="https://www.geeksforgeeks.org/introduction-to-stack-data-structure-and-algorithm-tutorials/">online</a>
</p>

<h3>The implementation</h3>

<p>
    The reason we need the run time stack is to implement the lifecycle of functions, so what happens when we call and return from a function, etc... 
    We know that a program usually consists of many subroutines (functions), and all of these subroutines fill out a specific goal within the program.
    Let's say a function called <i>y</i> starts it's life when called by another function: <i>x</i>, <i>y</i> is the callee and <i>x</i> is the caller.
    the callee can define it's own local variables which are private, and thse variables can be removed from memory once the callee returns.
</p>

<p>
    So, when the callee returns, the processor needs to know when it finishes and the location of the code that we should return to (which is usually right after the function call)
</p>

<p>
    In x86, each process will have it's own run-time stack, this is a memory region that obays the rules of the stack data structure.
    The run time-stack is divided into multiple small stacks, these are called "stack frames", each stack frame relates to a function that has been called during 
    execution, once the function ends it is removed from the larger run-time stack, therefore removing it from memory.
</p>

<p>
    The register <span class="hljs">EBP</span> (stack frame base pointer) caintains the starting memory address of the current stack frame, the register <span class="hljs">ESP</span> 
    contains the memory address of the top of the stack. To push a new item to the stack the <span class="hljs">push</span> instruction can be used, where the operand is the new item, this 
    will decrement the value of ESP to get a new starting address for the next value, this means that the value of the x86 run time stack grows down in memory.
</p>

<p>
    The <span class="hljs">pop</span> inscrution can also be used, this will increment the value of the ESP and store the value that was on the top of the stack to the memory location 
    or register specified by the operand.
    It also won't overwrite the popped value with null data, it will just leave it, this is for performance as writing a bunch of 0's in the place would take up unnessesary recourses,
    when we can just change the existing data when overwriting in the future.
</p>

<h4>The cdecl calling convention</h4>

<p>
    When a function needs to call another the caller should push all the parameters that should be passed to be into the callee to the stack. So, the callee's parameters will be on A's stack 
    frame. It's also worth noting that parameters are pushed in revered order, so parameter 2 will appear below parameter 1 on the stack frame. After this, the <span class="hljs">call</span> 
    instruction is used to start running the code of the other function, but before jumping, the instruction pushes the value of the return address onto the stack, which would be stored in 
    the program counter (EIP), this is done so we know where to go next after we are done executing our code.
</p>

<p>
    When a function starts in a program, it is responsible to create it's own stack frame, so the first thing a function should have in it's code is the code that makes a new stack frame.
    A function does this by pushing the current value of EBP to the stack frame, this is because it's going to be changed in a second,
    then we move the value of ESP (stack pointer) to EBP (starting address of the current stack frame).
    So now, we can continue working with our function and it's stack pointer now, pushing any value we may need, etc..
</p>

<p>
    You may be thinking: "but how do we reach our peramaters if they are further down the stack?", well this is where the EBP register comes in, as we can use this to access our parameters, 
    by referencing an incremented value of it, which would always be the same as only the prior EBP and return address are stored between the current value of the EBP and the required parameters.
</p>

<p>
    It's also worth noting that all values pushed to the stack are worth 4 bytes, as we are in 32 bit protected mode, 
    so to reach a parameter using EBP we can do EBP + 8 as the value of the EBP, moves in bytes, you may think we need to add 12 to reach the starting address of the first parameter,
    but remember the stack grows downwards, and the data would be stored upwards.
</p>

<p>
    When the callee needs to return any sort of value, we can just store it in a register like EAX, then to actually return we can just pop all the values from the stack 
    until we get to the prior value of EBP, this can then be popped into the actual EBP register. Then at the top of the stack is the memory address we need to return to,
    so this can just be loaded into the program counter, this can be done using the x86 instruction called <span class="hljs">RET</span> (which will also pop the value so 
    we will not need to pop it ourselves)
</p>

<p>
    Then when our caller gets control again, we can pop our previous parameters, just so we can clear up some memory space for the remainder of the function, you would expect to use pop, 
    but it can be done just by incrementing the stack pointer by 4 and this dealocates the memory without having to store it somewhere (as pop stores the values and removes them).
</p>

<p>
    The implementation of calling and returning from functions is not written in stone for x86, it is simply a convention, this one is known as cdecl, or the C declaration.
    There are many other conventions and you can even make/design your own.
</p>

